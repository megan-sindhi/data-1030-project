{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4bbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ae58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/default of credit card clients.xls\", header = 1)\n",
    "\n",
    "df = df.rename(columns={'default payment next month': 'DEFAULT'})\n",
    "df['EDUCATION'] = df['EDUCATION'].replace([5],4) ##5 and 6 are also others which is what 4 is\n",
    "df['EDUCATION'] = df['EDUCATION'].replace([6],4)\n",
    "X = df.drop(columns = ['DEFAULT','ID'])\n",
    "y= df['DEFAULT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_ftrs = ['SEX','EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2' ,'PAY_3', 'PAY_4','PAY_5','PAY_6']\n",
    "minmax_ftrs = ['AGE']\n",
    "std_ftrs = ['LIMIT_BAL','BILL_AMT1','BILL_AMT2' ,'BILL_AMT3','BILL_AMT4','BILL_AMT5' ,'BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3' ,'PAY_AMT4' ,'PAY_AMT5' ,'PAY_AMT6']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "prep = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70cd24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RF_f1(X, y, prep, param_grid):\n",
    "    '''\n",
    "    This function splits the data to train/val/test using stratified split\n",
    "    Gets best params using val\n",
    "    trains model\n",
    "    Gets test score \n",
    "    For 5 dif random states\n",
    "    '''\n",
    "    nr_states = 5\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "    \n",
    "    ##Split\n",
    "    for i in range(nr_states):\n",
    "        X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=37*i)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=37*i)\n",
    "\n",
    "        X_train_prep = prep.fit_transform(X_train)\n",
    "        X_val_prep = prep.transform(X_val)\n",
    "        X_test_prep = prep.transform(X_test)\n",
    "        train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        models = []\n",
    "        for p in range(len(ParameterGrid(param_grid))):\n",
    "            params = ParameterGrid(param_grid)[p] \n",
    "            clf = RandomForestClassifier(**params,random_state = 37*i,n_jobs=-1) # initialize the classifier\n",
    "            clf.fit(X_train_prep,y_train) # fit the model\n",
    "            models.append(clf) \n",
    "        # calculate train and validation fbeta scores\n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            train_score[p] = fbeta_score(y_train,y_train_pred, beta = 1)\n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            val_score[p] = fbeta_score(y_val,y_val_pred, beta = 1)\n",
    "    \n",
    "    # collect and save the best model\n",
    "        best_models.append(models[np.argmax(val_score)])\n",
    "    #calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test_prep)\n",
    "        test_scores[i] = fbeta_score(y_test,y_test_pred,beta=1)\n",
    "    return best_models, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c161a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##baseline f1 is 0.362296\n",
    "param_grid = {\n",
    "              'min_samples_leaf' : [1,2,5,10],\n",
    "              'max_depth': [1, 3, 10, 30, 100], # the max_depth should be smaller or equal than the number of features roughly\n",
    "              'max_features': [0.5,0.75,1.0] # linearly spaced between 0.5 and 1\n",
    "              } \n",
    "rf_bestmodels, rf_test_scores = RF_f1(X, y, prep, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d256b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44950495, 0.46461689, 0.47103877, 0.4691358 , 0.48390244])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9094a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def LogReg_f1(X, y, prep, param_grid, penalty):\n",
    "    '''\n",
    "    This function splits the data to train/val/test using stratified split\n",
    "    Gets best params using val\n",
    "    trains model\n",
    "    Gets test score \n",
    "    For 5 dif random states\n",
    "    '''\n",
    "    nr_states = 5\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "    \n",
    "    ##Split\n",
    "    for i in range(nr_states):\n",
    "        X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=37*i)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=37*i)\n",
    "\n",
    "        X_train_prep = prep.fit_transform(X_train)\n",
    "        X_val_prep = prep.transform(X_val)\n",
    "        X_test_prep = prep.transform(X_test)\n",
    "        train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        models = []\n",
    "        for p in range(len(ParameterGrid(param_grid))):\n",
    "            params = ParameterGrid(param_grid)[p] \n",
    "            clf = LogisticRegression(**params,penalty = penalty, random_state = 37*i,n_jobs=-1,solver = 'saga',max_iter = 100000) # initialize the classifier\n",
    "            clf.fit(X_train_prep,y_train) # fit the model\n",
    "            models.append(clf) \n",
    "        # calculate train and validation fbeta scores\n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            train_score[p] = fbeta_score(y_train,y_train_pred, beta = 1)\n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            val_score[p] = fbeta_score(y_val,y_val_pred, beta = 1)\n",
    "    \n",
    "    # collect and save the best model\n",
    "        best_models.append(models[np.argmax(val_score)])\n",
    "    # calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test_prep)\n",
    "        test_scores[i] = fbeta_score(y_test,y_test_pred, beta = 1)\n",
    "    return best_models, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82c7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]\n",
    "}\n",
    "l1_bestmodels, l1_test_scores = LogReg_f1(X, y, prep, param_grid, 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b03be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44095286, 0.4501992 , 0.478389  , 0.45708681, 0.46683292])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4843eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]\n",
    "}\n",
    "l2_bestmodels, l2_test_scores = LogReg_f1(X, y, prep, param_grid, 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6819ec74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44196655, 0.44897959, 0.4771274 , 0.45837414, 0.46859422])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ed7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "            'l1_ratio': [0.01, 0.1, 0.25, 0.5,0.75, 0.9, 0.99]\n",
    "}\n",
    "elasticnet_bestmodels, elasticnet_test_scores = LogReg_f1(X, y, prep, param_grid, 'elasticnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c04dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44196655, 0.4501992 , 0.47590954, 0.45383104, 0.46859422])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e25b79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KN_f1(X, y, prep, param_grid):\n",
    "    '''\n",
    "    This function splits the data to train/val/test using stratified split\n",
    "    Gets best params using val\n",
    "    trains model\n",
    "    Gets test score \n",
    "    For 5 dif random states\n",
    "    '''\n",
    "    nr_states = 5\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "    \n",
    "    ##Split\n",
    "    for i in range(nr_states):\n",
    "        X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=37*i)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=37*i)\n",
    "\n",
    "        X_train_prep = prep.fit_transform(X_train)\n",
    "        X_val_prep = prep.transform(X_val)\n",
    "        X_test_prep = prep.transform(X_test)\n",
    "        train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        models = []\n",
    "        for p in range(len(ParameterGrid(param_grid))):\n",
    "            params = ParameterGrid(param_grid)[p] \n",
    "            clf = KNeighborsClassifier(**params,n_jobs=-1) # initialize the classifier\n",
    "            clf.fit(X_train_prep,y_train) # fit the model\n",
    "            models.append(clf) \n",
    "        # calculate train and validation fbeta scores\n",
    "            y_train_pred = clf.predict(X_train_prep)\n",
    "            train_score[p] = fbeta_score(y_train,y_train_pred, beta = 1)\n",
    "            y_val_pred = clf.predict(X_val_prep)\n",
    "            val_score[p] = fbeta_score(y_val,y_val_pred, beta = 1)\n",
    "    \n",
    "    # collect and save the best model\n",
    "        best_models.append(models[np.argmax(val_score)])\n",
    "    #calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test_prep)\n",
    "        test_scores[i] = fbeta_score(y_test,y_test_pred,beta=1)\n",
    "    return best_models, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1e5e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'n_neighbors': [3, 10, 30, 100], \n",
    "              'weights':['uniform','distance']\n",
    "              } \n",
    "knn_bestmodels, knn_test_scores = KN_f1(X, y, prep, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a2a32b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41658537, 0.42367906, 0.41894531, 0.42569511, 0.43179588])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd83ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "def xgb_f1(X, y, prep, param_grid):\n",
    "    '''\n",
    "    This function splits the data to train/val/test using stratified split\n",
    "    Gets best params using val\n",
    "    trains model\n",
    "    Gets test score \n",
    "    For 5 dif random states\n",
    "    '''\n",
    "    nr_states = 5\n",
    "    test_scores = np.zeros(nr_states)\n",
    "    best_models = []\n",
    "    \n",
    "    ##Split\n",
    "    for i in range(nr_states):\n",
    "        X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=37*i)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=37*i)\n",
    "\n",
    "        X_train_prep = prep.fit_transform(X_train)\n",
    "        X_val_prep = prep.transform(X_val)\n",
    "        X_test_prep = prep.transform(X_test)\n",
    "        train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "        models = []\n",
    "        for p in range(len(ParameterGrid(param_grid))):\n",
    "            XGB = xgboost.XGBClassifier()\n",
    "            XGB.set_params(**ParameterGrid(param_grid)[p],objective = 'binary:hinge',random_state = 37*i)\n",
    "            XGB.fit(X_train_prep,y_train,early_stopping_rounds=50,eval_set=[(X_val_prep, y_val)], verbose=False, eval_metric = 'auc')\n",
    "            y_val_pred = XGB.predict(X_val_prep)\n",
    "            val_score[p] = fbeta_score(y_val,y_val_pred,beta=1)\n",
    "            models.append(XGB)\n",
    "    # collect and save the best model\n",
    "        best_models.append(models[np.argmax(val_score)])\n",
    "    #calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test_prep)\n",
    "        test_scores[i] = fbeta_score(y_test,y_test_pred,beta=1)\n",
    "    return best_models, test_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "942f6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"learning_rate\": [0.03],\n",
    "              \"n_estimators\": [10000],\n",
    "              \"seed\": [1354],\n",
    "              \"reg_alpha\": [0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "              #\"reg_lambda\": [0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "              #\"missing\": [np.nan], \n",
    "              \"max_depth\": [1,3,10,30,100],\n",
    "              \"colsample_bytree\": [0.5, 0.7,0.9],              \n",
    "              \"subsample\": [0.5, 0.66, 0.75, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5edb8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bestmodels, xgb_test_scores = xgb_f1(X, y, prep, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "505b4fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5158371 , 0.53190755, 0.53474837, 0.53266998, 0.54961295])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33aaeeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_bestmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0468ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.03, max_delta_step=0, max_depth=30,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10000, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:hinge', random_state=1354, reg_alpha=0.1,\n",
       "              reg_lambda=1, scale_pos_weight=3.5454545454545454, seed=1354,\n",
       "              subsample=0.66, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = [rf_test_scores.mean(), l1_test_scores.mean(), l2_test_scores.mean(), elasticnet_test_scores.mean(),knn_test_scores.mean(),xgb_test_scores.mean()]\n",
    "sds = [rf_test_scores.std(), l1_test_scores.std(), l2_test_scores.std(), elasticnet_test_scores.std(),knn_test_scores.std(),xgb_test_scores.std()]\n",
    "names = ['RF', 'L1', 'L2', 'Elastic','KNN','XGB' ]\n",
    "xpos = np.arange(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1c6dfef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xpos, means, yerr=sds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_xticks(xpos)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_title('Test Score Mean and SD')\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../figures/model_comparison.png', dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c33bb643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
